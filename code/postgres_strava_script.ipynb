{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from fitparse import FitFile\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "# in terminal need to create a database in postgres??:\n",
    "# > psql postgres\n",
    "# > CREATE DATABASE database_name;\n",
    "\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "DB_USER = 'bac'\n",
    "DB_NAME = 'starter_project'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "\n",
    "ACTIVITIES_FILE = 'activities.csv'\n",
    "FIT_FILES_FOLDER = 'path/to/your/fit_files/'\n",
    "\n",
    "IMPORTANT_FIELDS = ['heart_rate', 'cadence', 'speed']\n",
    "\n",
    "# SQLAlchemy engine (no warnings)\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def create_tables():\n",
    "    \"\"\"Create activities and fit_logs tables if not exist.\"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS activities (\n",
    "                activity_id SERIAL PRIMARY KEY,\n",
    "                name TEXT,\n",
    "                date TIMESTAMP,\n",
    "                distance FLOAT,\n",
    "                duration FLOAT,\n",
    "                fit_filename TEXT UNIQUE\n",
    "            )\n",
    "        \"\"\"))\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS fit_logs (\n",
    "                log_id BIGSERIAL PRIMARY KEY,\n",
    "                activity_id INTEGER REFERENCES activities(activity_id),\n",
    "                timestamp TIMESTAMP,\n",
    "                field_name TEXT,\n",
    "                field_value FLOAT\n",
    "            )\n",
    "        \"\"\"))\n",
    "    print(\"‚úÖ Tables ready.\")\n",
    "\n",
    "def load_activities():\n",
    "    \"\"\"Load activities.csv into the database.\"\"\"\n",
    "    df = pd.read_csv(ACTIVITIES_FILE)\n",
    "\n",
    "    # Make sure fit_filename is present\n",
    "    if 'fit_filename' not in df.columns:\n",
    "        raise ValueError(\"activities.csv must have a 'fit_filename' column.\")\n",
    "\n",
    "    # Insert into DB\n",
    "    df.to_sql('activities', engine, if_exists='append', index=False, method='multi')\n",
    "    print(f\"‚úÖ Inserted {len(df)} activities.\")\n",
    "\n",
    "def parse_fit_file(filepath):\n",
    "    \"\"\"Parse a .fit file into structured log entries.\"\"\"\n",
    "    try:\n",
    "        fitfile = FitFile(filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to parse {filepath}: {e}\")\n",
    "        return []\n",
    "\n",
    "    entries = []\n",
    "    for record in fitfile.get_messages('record'):\n",
    "        timestamp = None\n",
    "        metrics = []\n",
    "\n",
    "        for field in record:\n",
    "            if field.name == 'timestamp':\n",
    "                timestamp = field.value\n",
    "            elif field.name in IMPORTANT_FIELDS and field.value is not None:\n",
    "                metrics.append((field.name, field.value))\n",
    "\n",
    "        if timestamp:\n",
    "            for field_name, field_value in metrics:\n",
    "                entries.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'field_name': field_name,\n",
    "                    'field_value': field_value\n",
    "                })\n",
    "\n",
    "    return entries\n",
    "\n",
    "def find_activity_id(filename, activities_df):\n",
    "    \"\"\"Match .fit filename to activity_id.\"\"\"\n",
    "    match = activities_df[activities_df['fit_filename'] == filename]\n",
    "    if not match.empty:\n",
    "        return match.iloc[0]['activity_id']\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No matching activity found for {filename}\")\n",
    "        return None\n",
    "\n",
    "def insert_fit_logs():\n",
    "    \"\"\"Loop over fit files, parse, and insert logs into the database.\"\"\"\n",
    "    activities_df = pd.read_sql(\"SELECT activity_id, fit_filename FROM activities\", engine)\n",
    "\n",
    "    fit_files = glob.glob(os.path.join(FIT_FILES_FOLDER, '*.fit'))\n",
    "\n",
    "    total_logs_inserted = 0\n",
    "\n",
    "    for filepath in fit_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        activity_id = find_activity_id(filename, activities_df)\n",
    "\n",
    "        if activity_id is None:\n",
    "            continue\n",
    "\n",
    "        logs = parse_fit_file(filepath)\n",
    "\n",
    "        if not logs:\n",
    "            continue\n",
    "\n",
    "        # Attach activity_id to each log\n",
    "        for log in logs:\n",
    "            log['activity_id'] = activity_id\n",
    "\n",
    "        logs_df = pd.DataFrame(logs)\n",
    "\n",
    "        # Insert in bulk\n",
    "        try:\n",
    "            logs_df.to_sql('fit_logs', engine, if_exists='append', index=False, method='multi')\n",
    "            total_logs_inserted += len(logs_df)\n",
    "            print(f\"‚úÖ Inserted {len(logs_df)} logs from {filename}\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"‚ö†Ô∏è Database error inserting {filename}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Total logs inserted: {total_logs_inserted}\")\n",
    "\n",
    "# --- MAIN FLOW ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_tables()\n",
    "    load_activities()\n",
    "    insert_fit_logs()\n",
    "    print(\"\\nüèÅ All done!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

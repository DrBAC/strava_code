{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b5cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import duckdb\n",
    "from fitparse import FitFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "DB_FILE = 'project_database.duckdb'\n",
    "ACTIVITIES_FILE = '../strava_data_dumps/STRAVA+export_8029714/activities.csv'\n",
    "FIT_FILES_FOLDER = '../strava_data_dumps/STRAVA+export_8029714/activities/'\n",
    "\n",
    "IMPORTANT_FIELDS = ['heart_rate', 'cadence', 'speed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3107adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect(DB_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0c75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def create_tables():\n",
    "    \"\"\"Create activities and fit_logs tables (DuckDB compatible).\"\"\"\n",
    "    con.execute(\"DROP TABLE IF EXISTS activities\")\n",
    "    con.execute(\"DROP TABLE IF EXISTS fit_logs\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE activities (\n",
    "            activity_id BIGINT,\n",
    "            name TEXT,\n",
    "            date TIMESTAMP,\n",
    "            distance DOUBLE,\n",
    "            duration DOUBLE,\n",
    "            filename TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE fit_logs (\n",
    "            log_id BIGINT,\n",
    "            activity_id BIGINT,\n",
    "            timestamp TIMESTAMP,\n",
    "            field_name TEXT,\n",
    "            field_value DOUBLE\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(\"‚úÖ Tables created fresh.\")\n",
    "\n",
    "def get_next_id(table_name, id_column):\n",
    "    \"\"\"Find the next available ID for a table.\"\"\"\n",
    "    result = con.execute(f\"SELECT MAX({id_column}) FROM {table_name}\").fetchone()[0]\n",
    "    return 1 if result is None else result + 1\n",
    "\n",
    "def bulk_insert_activities(csv_path):\n",
    "    \"\"\"Load activities from CSV, assign activity_ids, and bulk insert.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if 'Filename' not in df.columns:\n",
    "        raise ValueError(\"activities.csv must have a 'filename' column.\")\n",
    "\n",
    "    next_id = get_next_id('activities', 'activity_id')\n",
    "    df.insert(0, 'activity_id', range(next_id, next_id + len(df)))\n",
    "\n",
    "    con.register('temp_activities', df)\n",
    "    con.execute(\"INSERT INTO activities SELECT * FROM temp_activities\")\n",
    "\n",
    "    print(f\"‚úÖ Inserted {len(df)} activities starting at ID {next_id}\")\n",
    "\n",
    "def parse_fit_file(filepath):\n",
    "    \"\"\"Parse a .fit file into a list of records.\"\"\"\n",
    "    try:\n",
    "        fitfile = FitFile(filepath)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to parse {filepath}: {e}\")\n",
    "        return []\n",
    "\n",
    "    entries = []\n",
    "    for record in fitfile.get_messages('record'):\n",
    "        timestamp = None\n",
    "        metrics = []\n",
    "\n",
    "        for field in record:\n",
    "            if field.name == 'timestamp':\n",
    "                timestamp = field.value\n",
    "            elif field.name in IMPORTANT_FIELDS and field.value is not None:\n",
    "                metrics.append((field.name, field.value))\n",
    "\n",
    "        if timestamp:\n",
    "            for field_name, field_value in metrics:\n",
    "                entries.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'field_name': field_name,\n",
    "                    'field_value': field_value\n",
    "                })\n",
    "\n",
    "    return entries\n",
    "\n",
    "def build_all_fit_logs():\n",
    "    \"\"\"Parse all .fit files into one big DataFrame of logs.\"\"\"\n",
    "    activities_df = pd.read_sql(\"SELECT activity_id, filename FROM activities\", con)\n",
    "\n",
    "    all_logs = []\n",
    "\n",
    "    fit_files = glob.glob(os.path.join(FIT_FILES_FOLDER, '*.fit'))\n",
    "\n",
    "    for filepath in fit_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        match = activities_df[activities_df['Filename'] == filename]\n",
    "\n",
    "        if match.empty:\n",
    "            print(f\"‚ö†Ô∏è No matching activity for {filename}\")\n",
    "            continue\n",
    "\n",
    "        activity_id = match.iloc[0]['activity_id']\n",
    "        logs = parse_fit_file(filepath)\n",
    "\n",
    "        if not logs:\n",
    "            continue\n",
    "\n",
    "        for log in logs:\n",
    "            log['activity_id'] = activity_id\n",
    "\n",
    "        all_logs.extend(logs)\n",
    "\n",
    "    print(f\"‚úÖ Parsed {len(all_logs)} total log entries from FIT files.\")\n",
    "    return pd.DataFrame(all_logs)\n",
    "\n",
    "def bulk_insert_fit_logs(df_logs):\n",
    "    \"\"\"Bulk insert fit logs with auto-incremented log_ids.\"\"\"\n",
    "    if df_logs.empty:\n",
    "        print(\"‚ö†Ô∏è No logs to insert.\")\n",
    "        return\n",
    "\n",
    "    next_id = get_next_id('fit_logs', 'log_id')\n",
    "    df_logs.insert(0, 'log_id', range(next_id, next_id + len(df_logs)))\n",
    "\n",
    "    con.register('temp_fit_logs', df_logs)\n",
    "    con.execute(\"INSERT INTO fit_logs SELECT * FROM temp_fit_logs\")\n",
    "\n",
    "    print(f\"‚úÖ Inserted {len(df_logs)} logs starting at ID {next_id}\")\n",
    "\n",
    "def test_query():\n",
    "    \"\"\"Query activities joined with fit_logs.\"\"\"\n",
    "    df = con.execute(\"\"\"\n",
    "        SELECT a.name, f.timestamp, f.field_name, f.field_value\n",
    "        FROM activities a\n",
    "        JOIN fit_logs f ON a.activity_id = f.activity_id\n",
    "        ORDER BY a.activity_id, f.timestamp\n",
    "        LIMIT 10\n",
    "    \"\"\").fetchdf()\n",
    "    print(\"\\nüéØ Sample joined data:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68796acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tables created fresh.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'strava_data_dumps/STRAVA+export_8029714/activities.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     create_tables()\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mbulk_insert_activities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mACTIVITIES_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     logs_df \u001b[38;5;241m=\u001b[39m build_all_fit_logs()\n\u001b[1;32m      7\u001b[0m     bulk_insert_fit_logs(logs_df)\n",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m, in \u001b[0;36mbulk_insert_activities\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbulk_insert_activities\u001b[39m(csv_path):\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load activities from CSV, assign activity_ids, and bulk insert.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilename\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivities.csv must have a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/PYTHON_PROJECTS/Strava_Analysis/strava_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PYTHON_PROJECTS/Strava_Analysis/strava_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/PYTHON_PROJECTS/Strava_Analysis/strava_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/PYTHON_PROJECTS/Strava_Analysis/strava_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/PYTHON_PROJECTS/Strava_Analysis/strava_env/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'strava_data_dumps/STRAVA+export_8029714/activities.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- MAIN FLOW ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_tables()\n",
    "    bulk_insert_activities(ACTIVITIES_FILE)\n",
    "    logs_df = build_all_fit_logs()\n",
    "    bulk_insert_fit_logs(logs_df)\n",
    "    test_query()\n",
    "    print(\"\\nüèÅ All done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7570382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5a80f",
   "metadata": {},
   "source": [
    "# Basic DuckDB example -- Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba31806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to a DuckDB database file (it will create it if it doesn't exist)\n",
    "con = duckdb.connect('test_project.duckdb')\n",
    "\n",
    "# Drop tables if they exist (to start fresh)\n",
    "con.execute(\"DROP TABLE IF EXISTS activities\")\n",
    "con.execute(\"DROP TABLE IF EXISTS fit_logs\")\n",
    "\n",
    "# Create activities table (MINIMAL, NO constraints)\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE activities (\n",
    "        activity_id BIGINT,\n",
    "        name TEXT,\n",
    "        date TIMESTAMP,\n",
    "        distance DOUBLE,\n",
    "        duration DOUBLE,\n",
    "        fit_filename TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Create fit_logs table (also MINIMAL)\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE fit_logs (\n",
    "        log_id BIGINT,\n",
    "        activity_id BIGINT,\n",
    "        timestamp TIMESTAMP,\n",
    "        field_name TEXT,\n",
    "        field_value DOUBLE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tables created successfully.\")\n",
    "\n",
    "# Insert one fake record into activities\n",
    "con.execute(\"\"\"\n",
    "    INSERT INTO activities (activity_id, name, date, distance, duration, fit_filename)\n",
    "    VALUES (1, 'Morning Run', NOW(), 5.0, 30.0, 'run01.fit')\n",
    "\"\"\")\n",
    "\n",
    "# Insert one fake record into fit_logs\n",
    "con.execute(\"\"\"\n",
    "    INSERT INTO fit_logs (log_id, activity_id, timestamp, field_name, field_value)\n",
    "    VALUES (1, 1, NOW(), 'heart_rate', 145)\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Inserted example data.\")\n",
    "\n",
    "# Query and print\n",
    "df = con.execute(\"\"\"\n",
    "    SELECT a.name, f.timestamp, f.field_name, f.field_value\n",
    "    FROM activities a\n",
    "    JOIN fit_logs f ON a.activity_id = f.activity_id\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nüéØ Query result:\")\n",
    "print(df)\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strava_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
